# Path to the whisper.cpp binary
# Use the whisper.cpp container
WHISPER_API_URL=http://localhost:9000
WHISPER_API_LANGUAGE=
WHISPER_API_TASK=transcribe
WHISPER_API_WORD_TS=true 

# Ollama (OpenAI-compatible) endpoint
API_BASE=http://localhost:11434/v1
# Ollama doesn't need a real key, but the SDK/client expects something
OPENAI_API_KEY=ollama
# Model served by Ollama (change to what you pulled)
LLM_MODEL=gpt-oss:20b

# Uncomment the block below to use OpenAI's API instead of Ollama
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-5
# API_BASE=https://api.openai.com/v1


# Where outputs are written
OUT_DIR=./dist
